---
excerpt: "기초 통계학 개념"
tag: [statistics]
use_math: true
published: true

---

## 앞서서

[KMOOC, R을 활용한 통계학개론](http://www.kmooc.kr/courses/course-v1:PNUk+RS_C01+2022_KM_021/course/) 을 보고있다. 그런데 내용도 간단해서 여기다가 간략히 메모한다.


## 자료의 정리

### 종류

+ Quantitative Data
  + Continuous / Discrete Data 로 나뉜다.
+ Qualitative 
  + Nominal / Ordinal Data. 전자는 범주 구분용으로 값이 사용되고, 후자는 범주가 가진 특징(ex. 순서) 가 반영되도록 값을 부여한 데이터이다.

### 지표

q-Quantile 은 전체를 ```q``` 개의 균등한 갯수의 부분집합으로 나눈다.
+ 4-Quantile 에서는 ```Q1```, ```Q2```, ```Q3``` 의 구분자가 있고 ```Q3-Q1``` 을 ```IQR(InterQuartile Range)``` 또는 Middle Fifty 라고 한다. 10-Quatile 에서는 ```D```, 100-Quatile 에서는 ```P``` 접두사를 쓴다. 
+ 2-Quantile 은 Median 이라고도 불린다. 전체 갯수가 짝수이면 ```n/2```, ```(n+1)/2``` 번째 값의 평균을 사용하는데 
+ 이때 Sample Quantile 을 구하는 법은 헷갈리기 쉽다. ```qn``` 이 소수이면 소숫점을 올린 번째의 값을 쓴고, 아니면 ```qn/2``` 와 ```(qn+1)/2``` 번째의 평균을 보통 채택한다. 헷갈리면 Median 구하는 법을 생각해보자.
+ ```quantile(datas, percentages)```, ```fivenum(datas)```, ```summary(datas)``` 로 값을 얻을 수 있다.

분포의 치우침을 ```skewness``` 로 표현한다. 평균이 중앙값보다 크면 평평한 꼬리가 오른쪽(큰 값)에 걸쳐있어 skewed-to-the-right 또는 positivly skewed 라고도 한다.  

Correlation 은 $$ \cfrac{ \mathrm{Cov}[X, Y] } { \sqrt{ \mathrm{Var}[X]} \sqrt{\mathrm{Var}[Y] } } $$ 으로 나타낸다. 
+ Sample / Population 인지에 따라 (공)분산은 ```n``` 으로 나눌지 ```n-1``` 로 갈리는데 Correlation 의 값은 차이가 없다. 
+ 선형변환에도 값을 유지하는 성질을 가진다.
+ 범위는 ```[-1, 1]``` 인데 증명은 생각보다 까다롭다.
+ ```cor(datas1, datas2)``` 로 값을 얻을 수 있다.

#### 그래프

+ Frequency table. ```table(datas)```
+ r x c Contingency Table. 
  +오른쪽이랑 아래 부분에 부분합(Marginal) 을 넣고 오른쪽 아래 끝에 총갯수를 넣는 그런 표.

+ Pie chart. ```pie(datas, labels, main)```
+ Histogram. ```hist(datas)```
+ Stem and Leaf plot.  ```stem(datas)```
+ Box(-Whisker) Plot.```boxplot(datas, range)```.
  + 기본값으로 ```range``` 을 IQR 의 1.5 를 사용한다.



### 랜덤변수

확률변수 $$X$$ 의 k-th moment(K 차 적률) 은 $$E(X^k) = \int{x^k}f(x)dx $$ 이다.

확률변수 $$X$$ 의 k-th central moment(k 차 중심적률) 은 $$ E[(X-\mu)^k] = \int{(x-\mu)^kf(x)dx} $$ 이다.
+ Population Variance = 2th centeral moment - (1th moment)^2

쓰이는 용어를 정리하면
+ Population Mean/Variance 는 $$\mu$$, $$\sigma^2$$ 로 나타낸다. 
+ Sample Mean 는 $$m = \overline{X} = \cfrac{1}{n}\sum{X_i}$$ 으로 
+ Sample Variance 는 $$s^2 = \cfrac{1}{n-1}\sum{X_i - \overline{X}}^2$$ 으로 나타낸다. 
  + 왜 Degree of Freedom(d.f.) 가 $$n-1$$ 인가?
  + ```관측치 - 제약조건의 수``` 에서 평균이라는 하나의 제약조건


#### Standardized Random Variable

> $$Z = \cfrac{X - \mu}{\sigma}$$

표준화된 변수는 평균 0 과 분산 1을 갖게 됨.

$$Z$$ 로 변환 후에도 항상 같은 Distribution Function 이 되지는 않음 
+ __Normal Distribution 은 정규화 후에도 같은 Distribution Function 을 유지함.__

표준화하여 서로 다른 집단을 비교할 때 집단의 크기가 대략 20 이상이어야하고 각 집단이 동질적이어야지 유의미한 결과를 얻을 수 있다.



## Distribution


#### Bernoulli trial 

$$X$$ ~ $$B(n,p)$$ 에 대해서
+ pmf $$\quad f(x) = \binom{n, x}p^x(1-p)^(n-x) $$
+ $$\mu = np$$, $$\sigma^2 = np(1-p)$$

이항분포에서 시행횟수 $$n$$ 이 매우 커지고, $$p$$ 가 매우 작고 $$np = m$$ 이 되면 Poisson distribution 가 가까워진다.

이항분포에서 시행횟수 $$n$$ 이 매우 커지고, $$p$$ 가 매우 작지 않고 $$np = m$$ 이 되면 Normal distribution 가 가까워진다.(이항분포의 정규근사)
+ [증명](https://hsm-edu.tistory.com/63)


#### Poisson distribution

단위 시간/공간에서 발생하는 사건의 수를 나타내는 확률변수 $$X$$ 가 평균 $$m$$ 인 Poisson distribution 을 따를 때 
+ PMF $$X$$ ~ $$P(m)$$ 는 $$f(x) = \cfrac{e^{-m}m^x}{x!} $$
+ 이는 Taylor Series 인 $$e^m = \sum_{x=0}^{\infty} \cfrac{m^x}{x!}$$ 에서 양변을 $$e^m$$ 으로 나누면 얻을 수 있는 항이다.
+ $$\mu = \sigma^2 = m$$ 이 성립한다.

Poisson distribution 을 따르기 위한 조건
+ Independence. 단위 시간/공간에서 발생하는 사건의 수는 또 다른 단위 시간/공간에서 발생되는 사건의 수와 무관하다.
+ Lack of clustering. 동시에 두개 이상의 사건이 발생할 확률은 0 에 가깝다.
+ Constant Rate. 사건의 수의 평균 $$m$$ 은 모든 단위 시간/공간에서 일정하다.



#### Gaussian Distribution(Normal Distribution)

> $$f(x) = \cfrac{1}{\sigma\sqrt{2\pi}}\exp(-\cfrac{(x-\mu)^2}{2\sigma^2})$$ 

$$X$$ ~ $$N(\mu, \sigma^2)$$ 이라 표현.

정규분포의 적분은 어렵지만 정규화 후에도 모양을 유지한다. 그래서 $$\mu = 1$$ 이고 $$\sigma = 1$$ 인 그래프로 변환시켜 표준정규분포의 적분표를 사용한다.
+ $$Z_\alpha$$ 를 $$P(z > Z_\alpha) = \alpha$$ 를 만족하는 수로 정의
+ ```pnorm(x, mu, sigma), qnorm(quantile, mu, sigma)```


#### Student's t-distribution

> 임의표본 $$X_1, \cdots, X_n$$ 이 정규분포 $$N(\mu, \sigma^2)$$ 를 따를 경우 $$\gamma = \cfrac{\overline{X} - \mu}{\text{s.e.}(\overline{X})}$$ 는 Degree of Freedom $$n-1$$ 인 t 분포를 따르게 되며, $$T$$ ~ $$t(n-1)$$ 으로 표현.

표본의 크기가 작고 표본이 정규분포를 따른다는 가정하에 표본평균의 분포를 추정하는데 사용된다.

좌우 대칭이며 d.f. 가 무한히 커지만 $$N(0, 1)$$ 에 근사하며, 꼬리는 $$N(0, 1)$$ 보다 더 두꺼운 모양(Heavy-Tailed Distribution)이다.


## Statistical Inferences

모집단으로부터 표본을 추출하여 모집단의 특성을 나타내는 Parameter(모수, ex. $$\mu$$, $$\sigma$$)에 대한 여러가지 정보를 얻기위한 일련의 과정


### Sample Distribution

Parameter 에서 Sampling 하여 얻는 Statistic(통계량, ex. 표본평균, 표본분산) 에 대한 Distribution 이 중요함.

> Random Sampling 에서 $$E(\overline{X}) = \mu, \quad \text{Var}(\overline{X}) = \cfrac{\sigma^2}{n}$$ 가 만족됨

> 표본의 크기가 충분히 크면 근사적으로 $$N(\mu, \sigma^2 / n)$$ 을 따르게 된다. 이를 Central Limit Theorem(중심극한정리, CLT) 라고 한다.

보통 표본의 크기가 25보다 크면 사용할만 하다고 한다.


### Point Estimation

어떤 Parameter $$\theta$$ 에 대해 점 추정치 $$\hat{\theta} \equiv \hat{\theta}(X_1, \cdots X_n)$$ 가 $$E(\hat{\theta}) = \theta$$ 를 만족하면 _Unbiased_ 라고 함.

Parameter $$\theta$$ 의 $$100(1-\alpha)$$% _신뢰구간_ 은 $$P(L(\hat{\theta}) < \theta < U(\hat{\theta}) ) = 1 - \alpha$$ 를 만족하는 구간 $$(L(\hat{\theta}), U(\hat{\theta})) $$ 을 말함.

CLT 를 이용하면 정규분포 상에서 다음이 만족됨
+ $$
\begin{multline}
P(-z_{\alpha/2} < \cfrac{\overline{X}-\mu}{\sigma/\sqrt(n)} < z_{\alpha/2}) \simeq 1-\alpha  \\ \shoveleft
P(
\overline{X} -z_{\alpha/2} \cfrac{\sigma}{\sqrt(n)} 
< \mu <
\overline{X} + z_{\alpha/2} \cfrac{\sigma}{\sqrt(n)} 
)
 \simeq 1-\alpha 
\end{multline}
$$
+ 이때 $$\sigma$$ 를 모르는 경우 $$s$$ 를 사용함. 
+ 분모까지 합친 $$\text{s.e}(\overline{X}) = s/\sqrt(n)$$ 값을 _Standard Error_ 라고 함.

### Interval Estimation


## Statistical Hypothesis 

가설의 참과 거짓을 귀납법, 연역법 등으로 증명할 수 없고, 가장 가능성이 높은 결론을 통계 자료를 통해 내리는 과정
+ $$H_0$$ : 부정하고 싶은 문장. _Null Hypothesis(귀무가설)_
+ $$H_1$$ : 주장하고 싶은 문장. _Alternative Hypothesis(대립가설)_
+ Test Statistic(검정 통계량) : 귀모가설의 기각 여부를 결정하기 위해 사용되는 통계량. 보통 정규분포의 정규화된 값?을 사용.
+ Rejection Region(기각역) : $$H_0$$ 이 기각되고 $$H_1$$ 이 채택되는 영역

|결정|```H_0 = T``` | ```H_1 = T``` |
|------|---|---|
|```H_0``` 기각 | Type 1 Error  | 옳은 결정 |
|```H_0``` 채택 | 옳은 결정 | Type 2 Error  |

1종 오류 확률을 _Level of Significance(유의수준, $$\alpha$$$)_ 라고 하고, 2종 오류 확률을 ($$\beta$$) 라고 한다. 이 둘을 가능한 최소화하는 판단을 구하는 전략이 목표이다.

> 가능한 최적의 검정법 : $$\alpha$$ 를 0.01, 0.05 등으로 고정시키고 Power of Test(검정력, $$1-\beta$$) 를 최대화 시킨다.

기각역(Rejection Region) 은 ```H_0``` 을 기각하게 되는 검정통계량 상의 영역이고 채택역(Acceptence Region) 은 이의 여사건이 된다.

 Significance Probability(p-Value, 유의확률) 는 주어진 검정통계량을 기각시키기 위한 제 1종 오류의 최솟값을 말한다. 즉 작을수록 주장을 강하게 할 수 있다.
 + p-value < $$alpha$$  이면 주어진 유의수준 $$\alpha$$ 에서 귀무가설이 기각된다.

### 분산의 추론

정규분포를 따르는 표본에서 불편추정치인 표본분산 $$s^2 = \cfrac{1}{n-1}\sum(X_i - \overline{X})^2 $$ 을 구하기 위해선 chi-square 분포를 사용한다.
+ $$W \equiv \cfrac{(n-1)s^2}{\sigma^2} $$ 가 자유도가 $$n-1$$ 인 chi_square 분포를 따르며 이를 $$W ~ \chi^2(n-1)$$ 로 나타낸다.
+ 0 이상에서 정의되고 right-skewed 모양이다.

chi-square 분포를 이용해서 t-분포 (모표본평균 모르면 모평균을 대신 쓸 때의 분포)를 도출할 수 있다.

### Independent Two Sample Test

